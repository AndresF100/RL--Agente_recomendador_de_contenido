{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "\n",
    "# Datos de interacciones de usuarios con películas, \n",
    "# la best_movie_id es el id de la película vista en el mismo día con mejor calificación dada por el usuario\n",
    "data = pd.read_parquet(r\"Netflix_Prize_data\\netflix_data_sample.parquet\")\n",
    "\n",
    "# Datos de películas, contiene el id de la película, el año y el título\n",
    "def read_movie_titles(csv_file_path):\n",
    "\n",
    "    list_of_movies = []\n",
    "\n",
    "\n",
    "    # Open the CSV file for reading\n",
    "    with open(csv_file_path, mode='r', newline='') as file:\n",
    "        # Read the file line by line\n",
    "        for line in file:\n",
    "            # Strip any leading/trailing whitespace including newlines\n",
    "            line = line.strip()\n",
    "            \n",
    "            # Split the line into exactly 3 parts: first three fields and the rest\n",
    "            parts = line.split(',', 2)\n",
    "            \n",
    "            # Ensure that we have exactly 4 parts (the last part may contain commas)\n",
    "            if len(parts) == 3:\n",
    "                id_field = parts[0]\n",
    "                name_field = parts[1]\n",
    "                description_field = parts[2]\n",
    "                \n",
    "                list_of_movies.append((id_field, name_field, description_field))\n",
    "\n",
    "            else:\n",
    "                # Handle cases where the line does not contain enough commas\n",
    "                print(f'Unexpected line format: {line}')\n",
    "\n",
    "    movie_titles = pd.DataFrame(list_of_movies, columns=[\"movie_id\", \"year\", \"title\"])\n",
    "\n",
    "    return movie_titles\n",
    "\n",
    "movie_titles = read_movie_titles(r\"Netflix_Prize_data\\movie_titles.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Environment:\n",
    "    def __init__(self, data, movie_titles):\n",
    "        # el ambiente tiene en memoria el dataframe con los datos de las interacciones de usuarios\n",
    "        self.data = data\n",
    "\n",
    "        # se escoge como punto de partida cualquier contenido movie_id\n",
    "        self.initial_state = data.sample(1)[\"movie_id\"].iloc[0]\n",
    "\n",
    "        # se inicializa el estado actual con el estado inicial\n",
    "        self.state = self.initial_state\n",
    "\n",
    "        # strikes controla la terminación del episodio, 1 strikes y el episodio termina\n",
    "        self.strikes = 0\n",
    "        # recompensa por defecto si se llega a 1 strike, está fuera (out)\n",
    "        self.reward_out = -10\n",
    "\n",
    "\n",
    "\n",
    "    def reset_strikes(self):\n",
    "        self.strikes = 0\n",
    "       \n",
    "    def is_terminal(self):\n",
    "        return self.strikes == 1\n",
    "\n",
    "    def get_current_state(self):\n",
    "        \"\"\"\n",
    "        Retorna el estado actual (el movie_id actual)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            Identificador de la película actual (movie_id)\n",
    "        \"\"\"\n",
    "        return self.state\n",
    "\n",
    "    def get_movie_name(self, movie_id):\n",
    "        \"\"\"\n",
    "        Retorna el nombre de la película dado el movie_id\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        movie_id : int\n",
    "            Identificador de la película\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            Nombre de la película\n",
    "        \"\"\"\n",
    "        return movie_titles[movie_titles.movie_id == movie_id].title.iloc[0]\n",
    "\n",
    "\n",
    "    def get_possible_actions(self, state):\n",
    "        \"\"\"\n",
    "        Retorna las acciones posibles dado un estado (movie_id), \n",
    "        las acciones serán cambiar a otro contenido dentro de los candidatos, los cuales son el grupo de películas con mejor calificación\n",
    "        media del usuario que ha calificado la película actual\n",
    "        \"\"\"\n",
    "        # obtener las películas candidatas, puntuación media dadas por los usuarios que vieron el contenido actual\n",
    "        candidates = data[data.movie_id == state].groupby(\"best_movie_id\")[\"best_rating\"].mean().sort_values(ascending=False)\n",
    "        # filtro para que solo se escojan las películas con mayor rating dentro del grupo de candidatos\n",
    "        candidates = candidates[(candidates==candidates.max())].index\n",
    "\n",
    "        return candidates\n",
    "    \n",
    "    def do_action(self, action):\n",
    "        \n",
    "        reward = 0\n",
    "        done = False\n",
    "\n",
    "        if self.is_terminal():\n",
    "            reward = self.reward_out\n",
    "            done = True\n",
    "        else:\n",
    "            # se obtiene la calificación media de los usuarios que vieron el contenido a recomendar\n",
    "            rating = self.data[self.data.movie_id == action].rating.mean()\n",
    "            # se escala la recompensa en función de la calificación media\n",
    "            reward = self.reward_scalation(rating)\n",
    "\n",
    "            # si el contenido recomendado tiene una calificación media menor a 3, se considera un strike para el agente,\n",
    "            # de lo contrario se reinician los strikes\n",
    "            if reward<0:\n",
    "                self.strikes += 1\n",
    "            else:\n",
    "                self.reset_strikes()\n",
    "\n",
    "        # recordar que la acción es el cambio de contenido, el nuevo estado es el nuevo contenido (id_movie a recomendar)\n",
    "        self.state = action\n",
    "        return reward, self.state, done\n",
    "\n",
    "\n",
    "    def reward_scalation(self, rating):\n",
    "        # la escala retorna 1 si el rating medio es 5, 0 si es 3 y -1 si es 1\n",
    "        return (rating-3)/2\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = self.initial_state\n",
    "\n",
    "\n",
    "\n",
    "# agente\n",
    "\n",
    "        \n",
    "class Agent:\n",
    "    def __init__(self, env, gamma=0.9, alpha=0.1, epsilon=0.9, episodes=1000):\n",
    "\n",
    "        # el agente tiene en memoria el ambiente\n",
    "        self.environment = env\n",
    "        # gamma factor de descuento\n",
    "        self.gamma = gamma\n",
    "        # alpha tasa de aprendizaje\n",
    "        self.alpha = alpha\n",
    "        # epsilon factor de exploración\n",
    "        self.epsilon = epsilon\n",
    "        # decay_rate tasa de decaimiento de epsilon\n",
    "        self.decay_rate = 0.9\n",
    "\n",
    "        # número de episodios\n",
    "        self.episodes = episodes\n",
    "        # Q table inicializada como un diccionario vacío, los estados y acciones se irán añadiendo a medida que se vayan explorando (evita crear una tabla muy grande)\n",
    "        self.qtable ={}\n",
    "\n",
    "\n",
    "    def run(self):\n",
    "\n",
    "        for episode in range(self.episodes):\n",
    "            self.environment.reset()\n",
    "            # estado actual (movie_id actual)\n",
    "            state = self.environment.get_current_state()\n",
    "            # done indica si el episodio ha terminado (si el agente ha llegado a 3 strikes)\n",
    "            done = False\n",
    "\n",
    "            while not done:\n",
    "                # se escoge una acción (cambio de contenido) al azar o con base en la Q table determinado por epsilon\n",
    "                action = self.random_action(state)\n",
    "\n",
    "                reward, next_state, done = self.step(action)\n",
    "                \n",
    "                # si el estado no está en la Q table, se añade\n",
    "                if state not in self.qtable:\n",
    "                    self.qtable[state] = {action: 0}\n",
    "                else:\n",
    "                    # si la acción no está en la Q table, se añade\n",
    "                    if action not in self.qtable[state]:\n",
    "                        self.qtable[state][action] = 0\n",
    "\n",
    "                # valor del estado actual en la Q table\n",
    "                old_value = self.qtable[state][action]\n",
    "                # valor del estado siguiente en la Q table\n",
    "                next_max = max(self.qtable[next_state].values()) if next_state in self.qtable else 0\n",
    "                # cálculo del nuevo valor del estado actual con base en la ecuación de Bellman\n",
    "                new_value = old_value + self.alpha * (reward + self.gamma * next_max - old_value)\n",
    "\n",
    "\n",
    "                if action is not None:\n",
    "                    self.qtable[state][action] = new_value\n",
    "                else:\n",
    "                    self.qtable[state][action] = reward\n",
    "                    \n",
    "                state = next_state\n",
    "            \n",
    "            self.epsilon = max(self.epsilon * self.decay_rate,0.01)\n",
    "\n",
    "\n",
    "    def random_action(self, current_state):\n",
    "\n",
    "        possible_actions = self.environment.get_possible_actions(current_state)\n",
    "\n",
    "        # fase de exploración (adquirir conocimiento)\n",
    "        if random.uniform(0, 1) < self.epsilon:\n",
    "            return random.choice(possible_actions)\n",
    "        \n",
    "        # fase de explotación del conocimiento\n",
    "        else:\n",
    "            # si aún no tiene conocimiento del estado actual, se escoge una al azar    \n",
    "            if ~ (current_state in self.qtable.keys()):\n",
    "                best_action = random.choice(possible_actions)\n",
    "\n",
    "            # si ya tiene conocimiento, se escoge la acción con mayor valor\n",
    "            else:\n",
    "                max_value = max(self.qtable[current_state].values())\n",
    "                max_keys = [key for key, value in self.qtable[current_state].items() if value == max_value]\n",
    "                best_action = random.choice(max_keys)\n",
    "\n",
    "            return best_action\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def step(self, action):\n",
    "       \n",
    "        return self.environment.do_action(action)\n",
    "    \n",
    "    \n",
    "    def actions_values(self):\n",
    "\n",
    "        actions = {}\n",
    "        values = {}\n",
    "        recommended = {}\n",
    "        for state, action_values in self.qtable.items():\n",
    "            \n",
    "            # id de la película recomendada con mayor valor en la Q table por cada estado\n",
    "            max_action = max(action_values, key=action_values.get)\n",
    "            actions[state] = max_action\n",
    "            \n",
    "            values[state] = max(action_values.values())\n",
    "            \n",
    "            # nombre de película actual\n",
    "            actual_movie = self.environment.get_movie_name(state)\n",
    "            recommended[actual_movie] = self.environment.get_movie_name(max_action)\n",
    "        \n",
    "        return actions, values, recommended\n",
    "        \n",
    "\n",
    "        \n",
    "    # def max_action(self, current_state):\n",
    "    #     action_index = np.argmax(self.qtable[current_state]) \n",
    "    #     actions = self.environment.actions\n",
    "    #     return actions[action_index]\n",
    "\n",
    "    # def action_name(self, action_index):\n",
    "    #     return self.environment.actions[action_index]\n",
    "    \n",
    "    # def action_index(self, action):\n",
    "    #     actions = self.environment.actions\n",
    "    #     for i in range(len(actions)):\n",
    "    #         if actions[i] == action:\n",
    "    #             return i\n",
    "    #     return -1\n",
    "\n",
    "\n",
    "\n",
    "env = Environment(data, movie_titles)\n",
    "\n",
    "#creación del agente\n",
    "agent = Agent(env, gamma=0.9, alpha=0.1, epsilon=0.9, episodes=10) #episodios reducidos para efectos de demostración\n",
    "#ejecución del agente\n",
    "agent.run()\n",
    "actions, values, recommended = agent.actions_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'5294': {'4356': 0.02860183366077276,\n",
       "  '3962': -1.0,\n",
       "  '62': -1.9,\n",
       "  '2195': -1.0,\n",
       "  '1299': -1.0,\n",
       "  '334': -1.9,\n",
       "  '17405': -1.0,\n",
       "  '1645': -1.0},\n",
       " '4356': {'406': 0.017293777134587553},\n",
       " '406': {'700': 0.019921875000000002},\n",
       " '700': {'330': 0.012903225806451625},\n",
       " '330': {'12494': 0.024461057023643942},\n",
       " '12494': {'6974': 0.06683501683501683},\n",
       " '6974': {'16147': 0.06978798586572439},\n",
       " '16147': {'789': 0.03074034334763949},\n",
       " '789': {'2813': 0.009728506787330327},\n",
       " '2813': {'357': 0.007231149567367124},\n",
       " '357': {'12672': 0.030307406643284508},\n",
       " '12672': {'992': 0.03220338983050848},\n",
       " '992': {'5582': 0.07257942511346448},\n",
       " '5582': {'1329': 0.011158798283261807},\n",
       " '1329': {'12870': 0.06966934487021015},\n",
       " '12870': {'8644': 0.03666435345824659},\n",
       " '8644': {'6552': 0.005783267827063444},\n",
       " '6552': {'1703': 0.03660772757039948},\n",
       " '1703': {'629': 0.018279569892473126},\n",
       " '629': {'1865': 0.018806354658651794},\n",
       " '1865': {'1707': 0.025694444444444443},\n",
       " '1707': {'7786': 0.041438356164383565},\n",
       " '7786': {'1642': 0.03958115183246074},\n",
       " '1642': {'12600': 0.033814303638644926},\n",
       " '12600': {'4881': 0.03089080459770115},\n",
       " '4881': {'5762': 0.037370867768595044},\n",
       " '5762': {'331': 0.020854826823876207},\n",
       " '331': {'12881': 0.018044747081712064},\n",
       " '12881': {'14737': 0.006776180698151957},\n",
       " '14737': {'2000': 0.027764026402640266},\n",
       " '2000': {'17381': 0.04338129496402879},\n",
       " '17381': {'11773': 0.025},\n",
       " '11773': {'10699': 0.03947368421052631},\n",
       " '10699': {'405': 0.01319999999999999},\n",
       " '405': {'4378': 0.025},\n",
       " '4378': {'6664': 0.044575471698113205},\n",
       " '6664': {'97': 0.02046979865771812},\n",
       " '97': {'2452': 0.06504730248018409},\n",
       " '2452': {'12299': 0.030652115332794397},\n",
       " '12299': {'2920': 0.023732251521298167},\n",
       " '2920': {'341': -0.012195121951219523},\n",
       " '341': {'798': -1.0}}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.qtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'5294': '4356',\n",
       " '4356': '406',\n",
       " '406': '700',\n",
       " '700': '330',\n",
       " '330': '12494',\n",
       " '12494': '6974',\n",
       " '6974': '16147',\n",
       " '16147': '789',\n",
       " '789': '2813',\n",
       " '2813': '357',\n",
       " '357': '12672',\n",
       " '12672': '992',\n",
       " '992': '5582',\n",
       " '5582': '1329',\n",
       " '1329': '12870',\n",
       " '12870': '8644',\n",
       " '8644': '6552',\n",
       " '6552': '1703',\n",
       " '1703': '629',\n",
       " '629': '1865',\n",
       " '1865': '1707',\n",
       " '1707': '7786',\n",
       " '7786': '1642',\n",
       " '1642': '12600',\n",
       " '12600': '4881',\n",
       " '4881': '5762',\n",
       " '5762': '331',\n",
       " '331': '12881',\n",
       " '12881': '14737',\n",
       " '14737': '2000',\n",
       " '2000': '17381',\n",
       " '17381': '11773',\n",
       " '11773': '10699',\n",
       " '10699': '405',\n",
       " '405': '4378',\n",
       " '4378': '6664',\n",
       " '6664': '97',\n",
       " '97': '2452',\n",
       " '2452': '12299',\n",
       " '12299': '2920',\n",
       " '2920': '341',\n",
       " '341': '798'}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'5294': 0.02860183366077276,\n",
       " '4356': 0.017293777134587553,\n",
       " '406': 0.019921875000000002,\n",
       " '700': 0.012903225806451625,\n",
       " '330': 0.024461057023643942,\n",
       " '12494': 0.06683501683501683,\n",
       " '6974': 0.06978798586572439,\n",
       " '16147': 0.03074034334763949,\n",
       " '789': 0.009728506787330327,\n",
       " '2813': 0.007231149567367124,\n",
       " '357': 0.030307406643284508,\n",
       " '12672': 0.03220338983050848,\n",
       " '992': 0.07257942511346448,\n",
       " '5582': 0.011158798283261807,\n",
       " '1329': 0.06966934487021015,\n",
       " '12870': 0.03666435345824659,\n",
       " '8644': 0.005783267827063444,\n",
       " '6552': 0.03660772757039948,\n",
       " '1703': 0.018279569892473126,\n",
       " '629': 0.018806354658651794,\n",
       " '1865': 0.025694444444444443,\n",
       " '1707': 0.041438356164383565,\n",
       " '7786': 0.03958115183246074,\n",
       " '1642': 0.033814303638644926,\n",
       " '12600': 0.03089080459770115,\n",
       " '4881': 0.037370867768595044,\n",
       " '5762': 0.020854826823876207,\n",
       " '331': 0.018044747081712064,\n",
       " '12881': 0.006776180698151957,\n",
       " '14737': 0.027764026402640266,\n",
       " '2000': 0.04338129496402879,\n",
       " '17381': 0.025,\n",
       " '11773': 0.03947368421052631,\n",
       " '10699': 0.01319999999999999,\n",
       " '405': 0.025,\n",
       " '4378': 0.044575471698113205,\n",
       " '6664': 0.02046979865771812,\n",
       " '97': 0.06504730248018409,\n",
       " '2452': 0.030652115332794397,\n",
       " '12299': 0.023732251521298167,\n",
       " '2920': -0.012195121951219523,\n",
       " '341': -1.0}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Tom and Jerry: Whiskers Away!': 'Road to Perdition',\n",
       " 'Road to Perdition': 'Hostage',\n",
       " 'Hostage': \"Todd McFarlane's Spawn\",\n",
       " \"Todd McFarlane's Spawn\": 'Wild Things',\n",
       " 'Wild Things': 'Behind Enemy Lines',\n",
       " 'Behind Enemy Lines': 'The Usual Suspects',\n",
       " 'The Usual Suspects': 'The Sopranos: Season 1',\n",
       " 'The Sopranos: Season 1': 'Boyz N the Hood',\n",
       " 'Boyz N the Hood': 'Bad Education',\n",
       " 'Bad Education': 'House of Sand and Fog',\n",
       " 'House of Sand and Fog': 'John Q',\n",
       " 'John Q': 'The Cowboys',\n",
       " 'The Cowboys': 'Star Wars: Episode V: The Empire Strikes Back',\n",
       " 'Star Wars: Episode V: The Empire Strikes Back': 'He Got Game',\n",
       " 'He Got Game': \"Schindler's List\",\n",
       " \"Schindler's List\": 'Catch Me If You Can',\n",
       " 'Catch Me If You Can': \"Charlie's Angels\",\n",
       " \"Charlie's Angels\": 'Ever After: A Cinderella Story',\n",
       " 'Ever After: A Cinderella Story': 'Firestarter',\n",
       " 'Firestarter': 'Eternal Sunshine of the Spotless Mind',\n",
       " 'Eternal Sunshine of the Spotless Mind': \"Outfoxed: Rupert Murdoch's War on Journalism\",\n",
       " \"Outfoxed: Rupert Murdoch's War on Journalism\": 'The Station Agent',\n",
       " 'The Station Agent': 'Casino: 10th Anniversary Edition',\n",
       " 'Casino: 10th Anniversary Edition': \"American Graffiti: Collector's Edition\",\n",
       " \"American Graffiti: Collector's Edition\": 'Crumb',\n",
       " 'Crumb': 'Almost Famous',\n",
       " 'Almost Famous': 'Chasing Amy',\n",
       " 'Chasing Amy': 'Moulin Rouge',\n",
       " 'Moulin Rouge': 'The Sweetest Thing',\n",
       " 'The Sweetest Thing': 'Four Weddings and a Funeral',\n",
       " 'Four Weddings and a Funeral': 'Spellbound',\n",
       " 'Spellbound': 'Passion of Anna',\n",
       " 'Passion of Anna': 'Smiles of a Summer Night',\n",
       " 'Smiles of a Summer Night': 'Wings of Desire',\n",
       " 'Wings of Desire': 'The Blue Kite',\n",
       " 'The Blue Kite': \"Babette's Feast\",\n",
       " \"Babette's Feast\": 'Mostly Martha',\n",
       " 'Mostly Martha': 'Lord of the Rings: The Fellowship of the Ring',\n",
       " 'Lord of the Rings: The Fellowship of the Ring': 'Along Came a Spider',\n",
       " 'Along Came a Spider': 'Baby Boom',\n",
       " 'Baby Boom': 'Tremors 4: The Legend Begins',\n",
       " 'Tremors 4: The Legend Begins': 'Jaws'}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommended"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
