{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje por Refuerzo\n",
    "## Sistema de Recomendación con Aprendizaje por Refuerzo Integrando Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in c:\\users\\ed\\.pyenv\\pyenv-win\\versions\\3.11.5\\lib\\site-packages (16.1.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\ed\\.pyenv\\pyenv-win\\versions\\3.11.5\\lib\\site-packages (from pyarrow) (1.26.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: c:\\Users\\Ed\\.pyenv\\pyenv-win\\versions\\3.11.5\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>best_movie_id</th>\n",
       "      <th>best_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14367</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>9340</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>571</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>9340</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2122</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>9340</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6972</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>9340</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15124</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>9340</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  movie_id customer_id  rating best_movie_id  best_rating\n",
       "0    14367          10       5          9340            5\n",
       "1      571          10       4          9340            5\n",
       "2     2122          10       4          9340            5\n",
       "3     6972          10       4          9340            5\n",
       "4    15124          10       4          9340            5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# librerías necesarias\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "\n",
    "# Datos de interacciones de usuarios con películas, \n",
    "# la best_movie_id es el id de la película vista en el mismo día con mejor calificación dada por el usuario\n",
    "data = pd.read_parquet(r\"Netflix_Prize_data\\netflix_data_sample.parquet\")\n",
    "# vista previa de los datos\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def __init__(self, data, movie_titles):\n",
    "        # el ambiente tiene en memoria el dataframe con los datos de las interacciones de usuarios\n",
    "        self.data = data\n",
    "\n",
    "        # se escoge como punto de partida cualquier contenido movie_id\n",
    "        self.initial_state = data.sample(1)[\"movie_id\"].iloc[0]\n",
    "\n",
    "        # se inicializa el estado actual con el estado inicial\n",
    "        self.state = self.initial_state\n",
    "\n",
    "        # strikes controla la terminación del episodio, 1 strikes y el episodio termina\n",
    "        self.strikes = 0\n",
    "        # recompensa por defecto si se llega a 1 strike, está fuera (out)\n",
    "        self.reward_out = -10\n",
    "\n",
    "        # se guardan los títulos de las películas para poder mostrarlas en el entorno\n",
    "        self.movie_titles = movie_titles\n",
    "\n",
    "\n",
    "\n",
    "    def reset_strikes(self):\n",
    "        \"\"\"\n",
    "        Reinicia los strikes a 0\n",
    "        \"\"\"\n",
    "        self.strikes = 0\n",
    "       \n",
    "    def is_terminal(self):\n",
    "        \"\"\"\n",
    "        Determina si el episodio ha terminado, si el agente ha llegado a 1 strike\n",
    "        \"\"\"\n",
    "        return self.strikes == 1\n",
    "\n",
    "    def get_current_state(self):\n",
    "        \"\"\"\n",
    "        Retorna el estado actual (el movie_id actual)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            Identificador de la película actual (movie_id)\n",
    "        \"\"\"\n",
    "        return self.state\n",
    "\n",
    "    def get_movie_name(self, movie_id):\n",
    "        \"\"\"\n",
    "        Retorna el nombre de la película dado el movie_id\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        movie_id : int\n",
    "            Identificador de la película\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            Nombre de la película\n",
    "        \"\"\"\n",
    "        return self.movie_titles[self.movie_titles.movie_id == movie_id].title.iloc[0]\n",
    "\n",
    "\n",
    "    def get_possible_actions(self, state):\n",
    "        \"\"\"\n",
    "        Retorna las acciones posibles dado un estado (movie_id), \n",
    "        las acciones serán cambiar a otro contenido dentro de los candidatos, los cuales son el grupo de películas con mejor calificación\n",
    "        media del usuario que ha calificado la película actual\n",
    "        \"\"\"\n",
    "        # obtener las películas candidatas, puntuación media dadas por los usuarios que vieron el contenido actual\n",
    "        candidates = data[data.movie_id == state].groupby(\"best_movie_id\")[\"best_rating\"].mean().sort_values(ascending=False)\n",
    "        # filtro para que solo se escojan las películas con mayor rating dentro del grupo de candidatos\n",
    "        candidates = candidates[(candidates==candidates.max())].index\n",
    "\n",
    "        return candidates\n",
    "    \n",
    "    def do_action(self, action):\n",
    "        \"\"\"\n",
    "        Realiza una acción en el entorno, cambiar de contenido a recomendar\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        action : int\n",
    "            Identificador de la película a recomendar (movie_id)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            Recompensa de realizar la acción\n",
    "        int\n",
    "            Nuevo estado (movie_id)\n",
    "        bool\n",
    "            True si el episodio ha terminado, False de lo contrario\n",
    "        \"\"\"\n",
    "        \n",
    "        reward = 0\n",
    "        done = False\n",
    "\n",
    "        if self.is_terminal():\n",
    "            # si es terminal, se asigna la recompensa por defecto y se termina el episodio\n",
    "            reward = self.reward_out\n",
    "            done = True\n",
    "        else:\n",
    "            # se obtiene la calificación media de los usuarios que vieron el contenido a recomendar\n",
    "            rating = self.data[self.data.movie_id == action].rating.mean()\n",
    "            # se escala la recompensa en función de la calificación media\n",
    "            reward = self.reward_scalation(rating)\n",
    "\n",
    "            # si el contenido recomendado tiene una calificación media menor a 3, se considera un strike para el agente,\n",
    "            # de lo contrario se reinician los strikes\n",
    "            if reward<0:\n",
    "                self.strikes += 1\n",
    "            else:\n",
    "                self.reset_strikes()\n",
    "\n",
    "        # recordar que la acción es el cambio de contenido, el nuevo estado es el nuevo contenido (id_movie a recomendar)\n",
    "        self.state = action\n",
    "        return reward, self.state, done\n",
    "\n",
    "\n",
    "    def reward_scalation(self, rating):\n",
    "        \"\"\"\n",
    "        Retorna la recompensa escalada en función de la calificación media de la película a recomendar\n",
    "        \"\"\"\n",
    "        # la escala retorna 1 si el rating medio es 5, 0 si es 3 y -1 si es 1\n",
    "        return (rating-3)/2\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Reinicia el entorno, el estado actual se reinicia al estado inicial\n",
    "        \"\"\"\n",
    "        self.state = self.initial_state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Agent:\n",
    "    def __init__(self, env, gamma=0.9, alpha=0.1, epsilon=0.9, episodes=1000, qtable=None):\n",
    "\n",
    "        # el agente tiene en memoria el ambiente\n",
    "        self.environment = env\n",
    "        # gamma factor de descuento\n",
    "        self.gamma = gamma\n",
    "        # alpha tasa de aprendizaje\n",
    "        self.alpha = alpha\n",
    "        # epsilon factor de exploración\n",
    "        self.epsilon = epsilon\n",
    "        # decay_rate tasa de decaimiento de epsilon\n",
    "        self.decay_rate = 0.9\n",
    "\n",
    "        # número de episodios\n",
    "        self.episodes = episodes\n",
    "\n",
    "        # Q-table se puede inicializar con valores ya entrenados del parámetro 'qtable'. \n",
    "        # Esto, junto a un valor de exploración pequeño, hará que el agente utilice esta política aprendida con antelación. \n",
    "        # Se inicializa como un diccionario vacío en caso de no recibir la política como parámetro, y \n",
    "        # los estados y acciones se irán añadiendo a medida que se vayan explorando (esto evita crear una tabla muy grande)\n",
    "        self.qtable = qtable if qtable is not None else {}\n",
    "\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Entrenamiento del agente, se ejecutan los episodios hasta la condición de terminación de cada uno y se actualiza la Q table\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            Q table con los valores de los estados y acciones aprendidos\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        for episode in range(self.episodes):\n",
    "            self.environment.reset()\n",
    "            # estado actual (movie_id actual)\n",
    "            state = self.environment.get_current_state()\n",
    "            # done indica si el episodio ha terminado (si el agente ha llegado a 3 strikes)\n",
    "            done = False\n",
    "\n",
    "            while not done:\n",
    "                # se escoge una acción (cambio de contenido) al azar o con base en la Q table determinado por epsilon\n",
    "                action = self.random_action(state)\n",
    "\n",
    "                reward, next_state, done = self.step(action)\n",
    "                \n",
    "                # si el estado no está en la Q table, se añade\n",
    "                if state not in self.qtable:\n",
    "                    self.qtable[state] = {action: 0}\n",
    "                else:\n",
    "                    # si la acción no está en la Q table, se añade\n",
    "                    if action not in self.qtable[state]:\n",
    "                        self.qtable[state][action] = 0\n",
    "\n",
    "                # valor del estado actual en la Q table\n",
    "                old_value = self.qtable[state][action]\n",
    "                # valor del estado siguiente en la Q table\n",
    "                next_max = max(self.qtable[next_state].values()) if next_state in self.qtable else 0\n",
    "                # cálculo del nuevo valor del estado actual con base en la ecuación de Bellman\n",
    "                new_value = old_value + self.alpha * (reward + self.gamma * next_max - old_value)\n",
    "\n",
    "\n",
    "                if action is not None:\n",
    "                    self.qtable[state][action] = new_value\n",
    "                else:\n",
    "                    self.qtable[state][action] = reward\n",
    "                    \n",
    "                state = next_state\n",
    "            # decaimiento de epsilon\n",
    "            self.epsilon = max(self.epsilon * self.decay_rate,0.01)\n",
    "\n",
    "        return self.qtable\n",
    "\n",
    "\n",
    "    def random_action(self, current_state):\n",
    "        \"\"\"\n",
    "        Retorna una acción al azar o con base en la Q table determinado por epsilon\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        current_state : int\n",
    "            Estado actual (movie_id actual)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            Acción a realizar (movie_id a recomendar)\n",
    "        \"\"\"\n",
    "\n",
    "        possible_actions = self.environment.get_possible_actions(current_state)\n",
    "\n",
    "        # fase de exploración (adquirir conocimiento)\n",
    "        if random.uniform(0, 1) < self.epsilon:\n",
    "            return random.choice(possible_actions)\n",
    "        \n",
    "        # fase de explotación del conocimiento\n",
    "        else:\n",
    "            # si aún no tiene conocimiento del estado actual, se escoge una al azar    \n",
    "            if ~ (current_state in self.qtable.keys()):\n",
    "                best_action = random.choice(possible_actions)\n",
    "\n",
    "            # si ya tiene conocimiento, se escoge la acción con mayor valor\n",
    "            else:\n",
    "                max_value = max(self.qtable[current_state].values())\n",
    "                max_keys = [key for key, value in self.qtable[current_state].items() if value == max_value]\n",
    "                best_action = random.choice(max_keys)\n",
    "\n",
    "            return best_action\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def step(self, action):       \n",
    "        \"\"\"\n",
    "        Realiza una acción en el entorno, cambiar de contenido a recomendar\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        action : int\n",
    "            Identificador de la película a recomendar (movie_id)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            Recompensa de realizar la acción\"\"\"\n",
    "\n",
    "        return self.environment.do_action(action)\n",
    "    \n",
    "\n",
    "    def actions_values(self):\n",
    "        \"\"\"\n",
    "        Retorna las películas recomendadas basándose en el valor más alto de todos los estados explorados\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            Diccionario con los estados y las acciones recomendadas\n",
    "        dict\n",
    "            Diccionario con los valores de los estados y acciones\n",
    "        dict\n",
    "            Diccionario con las películas recomendadas por cada película actual\n",
    "        \"\"\"\n",
    "\n",
    "        actions = {}\n",
    "        values = {}\n",
    "        recommended = {}\n",
    "        for state, action_values in self.qtable.items():\n",
    "            \n",
    "            # id de la película recomendada con mayor valor en la Q table por cada estado\n",
    "            max_action = max(action_values, key=action_values.get)\n",
    "            actions[state] = max_action\n",
    "            \n",
    "            values[state] = max(action_values.values())\n",
    "            \n",
    "            # nombre de película actual\n",
    "            actual_movie = self.environment.get_movie_name(state)\n",
    "            recommended[actual_movie] = self.environment.get_movie_name(max_action)\n",
    "        \n",
    "        return actions, values, recommended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones de persistencia de Q-Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones para persistir y cargar los datos de la q-table\n",
    "\n",
    "import json\n",
    "\n",
    "def save_qtable(qtable, file_name):\n",
    "    \"\"\"\n",
    "    Guarda la Q table en un archivo JSON\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    qtable : dict\n",
    "        Q table con los valores de los estados y acciones aprendidos\n",
    "    file_name : str\n",
    "        Nombre del archivo donde se guardará la Q table\n",
    "        \n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_name, 'w') as file:\n",
    "            json.dump(qtable, file, indent=4)\n",
    "        print(f\"Qtable ha sido guardado en {file_name}\")\n",
    "    except IOError as e:\n",
    "        print(f\"An error occurred while saving data to {file_name}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_qtable(file_name):\n",
    "    \"\"\"\n",
    "    Carga la Q table desde un archivo JSON\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_name : str\n",
    "        Nombre del archivo donde se encuentra la Q table\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Q table con los valores de los estados y acciones aprendidos\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_name, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "    except IOError as e:\n",
    "        print(f\"An error occurred while reading data from {file_name}: {e}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Datos de películas, contiene el id de la película, el año y el título\n",
    "def read_movie_titles(csv_file_path):\n",
    "    \"\"\"\n",
    "    Lee un archivo CSV con información de películas y retorna un DataFrame con los datos\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    csv_file_path : str\n",
    "        Ruta del archivo CSV\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame con los datos de las películas\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    list_of_movies = []\n",
    "\n",
    "    # Open the CSV file for reading\n",
    "    with open(csv_file_path, mode='r', newline='') as file:\n",
    "        # Read the file line by line\n",
    "        for line in file:\n",
    "            # Strip any leading/trailing whitespace including newlines\n",
    "            line = line.strip()\n",
    "            \n",
    "            # Split the line into exactly 3 parts: first three fields and the rest\n",
    "            parts = line.split(',', 2)\n",
    "            \n",
    "            # Ensure that we have exactly 4 parts (the last part may contain commas)\n",
    "            if len(parts) == 3:\n",
    "                id_field = parts[0]\n",
    "                name_field = parts[1]\n",
    "                description_field = parts[2]\n",
    "                \n",
    "                list_of_movies.append((id_field, name_field, description_field))\n",
    "\n",
    "            else:\n",
    "                # Handle cases where the line does not contain enough commas\n",
    "                print(f'Unexpected line format: {line}')\n",
    "\n",
    "    movie_titles = pd.DataFrame(list_of_movies, columns=[\"movie_id\", \"year\", \"title\"])\n",
    "\n",
    "    return movie_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qtable ha sido guardado en qtable.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Poirot: Lord Edgware Dies': 'Lilo and Stitch',\n",
       " 'Lilo and Stitch': 'Aqua Teen Hunger Force: Vol. 3',\n",
       " 'The Abyss': 'Buffy the Vampire Slayer: Season 6',\n",
       " 'Buffy the Vampire Slayer: Season 6': 'The Three Stooges: Sing a Song of Six Pants',\n",
       " 'The Three Stooges: Sing a Song of Six Pants': 'Lilo and Stitch',\n",
       " 'Aqua Teen Hunger Force: Vol. 3': 'La Strada: Special Edition',\n",
       " 'La Strada: Special Edition': 'Wallace & Gromit in Three Amazing Adventures',\n",
       " 'Wallace & Gromit in Three Amazing Adventures': 'Arrested Development: Season 2',\n",
       " 'Arrested Development: Season 2': \"America's Next Top Model: Cycle 1\",\n",
       " \"America's Next Top Model: Cycle 1\": 'Lord of the Rings: The Two Towers: Extended Edition',\n",
       " 'Lord of the Rings: The Two Towers: Extended Edition': 'Strange Brew',\n",
       " 'Strange Brew': 'The Bourne Identity',\n",
       " 'The Bourne Identity': 'Spider-Man 2',\n",
       " 'Spider-Man 2': 'Ace Ventura: Pet Detective',\n",
       " 'Ace Ventura: Pet Detective': 'Life or Something Like It',\n",
       " 'Life or Something Like It': 'Alias: Season 1',\n",
       " 'Alias: Season 1': 'Parenthood',\n",
       " 'Parenthood': 'Better Off Dead',\n",
       " 'Better Off Dead': 'Private Parts',\n",
       " 'Private Parts': 'Clerks',\n",
       " 'Clerks': 'Rudy',\n",
       " 'Rudy': 'When Harry Met Sally',\n",
       " 'When Harry Met Sally': 'Liar Liar',\n",
       " 'Liar Liar': 'Farscape: Season 4',\n",
       " 'Farscape: Season 4': 'Finding Nemo (Widescreen)',\n",
       " 'Finding Nemo (Widescreen)': 'Herbie Rides Again',\n",
       " 'Herbie Rides Again': \"Ken Burns' Civil War\",\n",
       " \"Ken Burns' Civil War\": 'Bambi: Platinum Edition',\n",
       " 'Bambi: Platinum Edition': 'The Godfather',\n",
       " 'The Godfather': 'Seabiscuit',\n",
       " 'Seabiscuit': 'The Man Who Knew Too Much',\n",
       " 'The Man Who Knew Too Much': 'Whale Rider',\n",
       " 'Whale Rider': 'Gilmore Girls: Season 1',\n",
       " 'Gilmore Girls: Season 1': 'Caddyshack',\n",
       " 'Caddyshack': \"The Hitchhiker's Guide to the Galaxy\",\n",
       " \"The Hitchhiker's Guide to the Galaxy\": 'Lord of the Rings: The Two Towers'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EJECUTAMOS EL AGENTE EN ESCENARIO DE ENTRENAMIENTO\n",
    "\n",
    "env = Environment(data, read_movie_titles(r\"Netflix_Prize_data\\movie_titles.csv\"))\n",
    "\n",
    "#creación del agente\n",
    "agent = Agent(env, gamma=0.9, alpha=0.1, epsilon=0.9, episodes=10) #episodios reducidos para efectos de demostración\n",
    "\n",
    "# Ejecución del agente y obtenemos la Q-table con la política encontrada por el agente\n",
    "qtable = agent.run()\n",
    "\n",
    "# La política de esta Q-table la guardamos para poder usarla después\n",
    "save_qtable(qtable, 'qtable.json')\n",
    "\n",
    "actions, values, recommended = agent.actions_values()\n",
    "recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Poirot: Lord Edgware Dies': 'Lilo and Stitch',\n",
       " 'Lilo and Stitch': 'Aqua Teen Hunger Force: Vol. 3',\n",
       " 'The Abyss': 'Buffy the Vampire Slayer: Season 6',\n",
       " 'Buffy the Vampire Slayer: Season 6': 'The Three Stooges: Sing a Song of Six Pants',\n",
       " 'The Three Stooges: Sing a Song of Six Pants': 'Lilo and Stitch',\n",
       " 'Aqua Teen Hunger Force: Vol. 3': 'La Strada: Special Edition',\n",
       " 'La Strada: Special Edition': 'Wallace & Gromit in Three Amazing Adventures',\n",
       " 'Wallace & Gromit in Three Amazing Adventures': 'Arrested Development: Season 2',\n",
       " 'Arrested Development: Season 2': \"America's Next Top Model: Cycle 1\",\n",
       " \"America's Next Top Model: Cycle 1\": 'Lord of the Rings: The Two Towers: Extended Edition',\n",
       " 'Lord of the Rings: The Two Towers: Extended Edition': 'Strange Brew',\n",
       " 'Strange Brew': 'The Bourne Identity',\n",
       " 'The Bourne Identity': 'Spider-Man 2',\n",
       " 'Spider-Man 2': 'Ace Ventura: Pet Detective',\n",
       " 'Ace Ventura: Pet Detective': 'Life or Something Like It',\n",
       " 'Life or Something Like It': 'Alias: Season 1',\n",
       " 'Alias: Season 1': 'Parenthood',\n",
       " 'Parenthood': 'Better Off Dead',\n",
       " 'Better Off Dead': 'Private Parts',\n",
       " 'Private Parts': 'Clerks',\n",
       " 'Clerks': 'Rudy',\n",
       " 'Rudy': 'When Harry Met Sally',\n",
       " 'When Harry Met Sally': 'Liar Liar',\n",
       " 'Liar Liar': 'Farscape: Season 4',\n",
       " 'Farscape: Season 4': 'Finding Nemo (Widescreen)',\n",
       " 'Finding Nemo (Widescreen)': 'Herbie Rides Again',\n",
       " 'Herbie Rides Again': \"Ken Burns' Civil War\",\n",
       " \"Ken Burns' Civil War\": 'Bambi: Platinum Edition',\n",
       " 'Bambi: Platinum Edition': 'The Godfather',\n",
       " 'The Godfather': 'Seabiscuit',\n",
       " 'Seabiscuit': 'The Man Who Knew Too Much',\n",
       " 'The Man Who Knew Too Much': 'Whale Rider',\n",
       " 'Whale Rider': 'Gilmore Girls: Season 1',\n",
       " 'Gilmore Girls: Season 1': 'Caddyshack',\n",
       " 'Caddyshack': \"The Hitchhiker's Guide to the Galaxy\",\n",
       " \"The Hitchhiker's Guide to the Galaxy\": 'Lord of the Rings: The Two Towers',\n",
       " 'Glory': \"Ben-Hur: Collector's Edition: Bonus Material\",\n",
       " \"Ben-Hur: Collector's Edition: Bonus Material\": 'MASH: Season 5',\n",
       " 'MASH: Season 5': \"Monty Python's Life of Brian\",\n",
       " \"Monty Python's Life of Brian\": 'Goldfinger',\n",
       " 'Goldfinger': 'The Goodbye Girl',\n",
       " 'The Goodbye Girl': 'Steel Magnolias',\n",
       " 'Steel Magnolias': 'The Deep End of the Ocean',\n",
       " 'The Deep End of the Ocean': 'Secondhand Lions',\n",
       " 'Secondhand Lions': 'The Rocky Horror Picture Show',\n",
       " 'The Rocky Horror Picture Show': 'Emma (Miniseries)',\n",
       " 'Emma (Miniseries)': 'Elizabeth',\n",
       " 'Elizabeth': 'The Cutting Edge',\n",
       " 'The Cutting Edge': 'CB4',\n",
       " 'CB4': 'Rear Window',\n",
       " 'Rear Window': \"Murphy's Romance\",\n",
       " \"Murphy's Romance\": 'Psycho',\n",
       " 'Psycho': 'Alias: Season 1',\n",
       " 'Igby Goes Down': 'Final Analysis',\n",
       " 'Final Analysis': 'Little Women',\n",
       " 'Little Women': 'Cirque du Soleil: Alegria',\n",
       " 'Cirque du Soleil: Alegria': 'The Best of Friends: Vol. 4',\n",
       " 'The Best of Friends: Vol. 4': 'Tuck Everlasting',\n",
       " 'Tuck Everlasting': 'The Professional',\n",
       " 'The Professional': 'Lucio Fulci: The Beyond',\n",
       " 'Lucio Fulci: The Beyond': 'The Poseidon Adventure'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EJECUTAMOS EL AGENTE EN ESCENARIO DE USAR LA POLÍTICA APRENDIDA EN ENTRENAMIENTO\n",
    "\n",
    "env = Environment(data, read_movie_titles(r\"Netflix_Prize_data\\movie_titles.csv\"))\n",
    "\n",
    "# Cargamos la política aprendida\n",
    "qtable = load_qtable('qtable.json')\n",
    "\n",
    "# creación del agente y pasamos la política como parámetro 'qtable'\n",
    "# En esta ocasión vamos a utilizar un valor de exploración pequeño (epsilon),\n",
    "# con el fin de que el agente explote la política encontrada lo más posible.\n",
    "agent = Agent(env, gamma=0.9, alpha=0.1, epsilon=0.1, episodes=10, qtable=qtable) #episodios reducidos para efectos de demostración\n",
    "\n",
    "#ejecución del agente\n",
    "agent.run()\n",
    "actions, values, recommended = agent.actions_values()\n",
    "recommended"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
